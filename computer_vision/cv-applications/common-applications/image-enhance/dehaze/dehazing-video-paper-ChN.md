# 视频实时去雾算法   

> 论文原文: ["Optimized Contrast Enhancement for Real-Time Image and Video Dehazing"](http://dx.doi.org/10.1016/j.jvcir.2013.02.004)  

直方图均衡化和边缘锐化通过拉伸直方图可以提高图像的对比度, 但是这些方法并没有考虑到图像深度和雾的厚度是成正比的.   

本文并不是基于暗通道去雾进行改进, 而是基于深度估计(场景中点相对于相机的距离)的场景辐射率恢复.   

## 1. 概述

目标深度越深, 雾的厚度也就越大. 即二者成正比关系.   

前期的工作是基于多张图来估计 depth, 因此算法需要的图像和额外信息相对较多, 在一定程度上限制了这类算法的应用. 目前已经发展出基于单张图的去雾算法, 并且克服了多张图去雾的缺点.   

单张图的去雾算法一般都基于很强的假设或约束.  

**What**   

作者要解决什么问题?  

(1) 目前存在的算法会导致过度拉伸图像对比度. 或者由于无法准确估计场景的深度, 完全无法去除比较浓厚的雾;   
(2) 目前的视频去雾算法的计算复杂度很高, 无法对高分辨率的图像应用去雾算法.  

**How**  

如何解决?  

(1) 针对过度拉伸对比度的问题. 通过优化对比度增强方式来自适应地控制图像对比度的增强程度;   
(2) 针对视频去雾算法的计算复杂度. 引入时间一致性 cost 到之前的 cost 函数中, 充分利用前一帧计算出的信息( A 和 t).   

**总结**一下本文算法的大致思路:   

- 对溢出上下界的像素作截断处理, 并设计 cost 函数来减少在最大化对比度过程中的像素信息失真程度;  
- 通过最小化 cost 函数来为每一个 block 找到一个最优的场景深度( 1/4 层级搜索 );   
- 对于 video dehaze, 假设相邻两帧之间场景中目标的辐射率是不变的, 额外引入时间一致性 cost 到之前的 cost 函数中;  
- 另外, 设计了一种并行计算方法来加速;   

## 2. 雾图模型 - Haze model    

基于大气光学, 可以对雾中观测到的彩色图像建模:   

$$\tag{1}
\textbf{I}(p) = t(p)\textbf{J}(p) + (1 - t(p))\textbf{A}
$$

其中:   
- $\textbf{J}(p) = (J_r(p), J_g(p), J_b(p))^T$ 是在像素点 p 处的原始图像颜色, 包含三个通道值(r, g, b);    
- $\textbf{I}(p) = (I_r(p), I_g(p), I_b(p))^T$ 是在像素点 p 处观察到的图像颜色, 包含三个通道值(r, g, b);    
- $\textbf{A} = (A_r, A_g, A_b)^T$ 是全局大气光照, 即大气周围的环境光照;   
- $t(p) \in [0,1]$ 是反射光的传输率, 也叫透射率.   

对于透射率 $t(p)$ 而言, 由于光在远距离的传输过程中会变得发散和稀薄. 因此, $t(p)$ 的值与 "场景深度"(场景中的点和相机的距离) 互为负相关. 场景点越深, $t(p)$ 越小.

$$\tag{2}
t(p) = e^{-\rho d(p)}
$$

其中,  
- $d(p)$ 是像素点 p 距离相机的场景深度;   
- $\rho$ 是衰减系数, 和天气状况有关, 一般选择 1 表示典型的有雾天气;   

对公式 (1) 的 **直观理解**: 

(1) 对于观察到的色彩. 观察到的色彩是物体本来的辐射色彩经过 $t(p)$ 稀薄之后得到;  
(2) 当场景点距离相机位置很远时, 使用 $1- t(p)$ 作为大气光照 A 的权重值对于计算观察到的颜色值的处理也是很关键的;   
(3) 如果透射率 $t(p)$ 的值无限接近 1, 说明场景点距离相机非常近, 则观察到的颜色中应该是原始图像颜色; 反之, 透射率的值无限接近 0, 观察到的颜色中应该是全局大气光照, 说明场景点距离相机非常远, 则观察的图像就是大气光照;  

由此可见, 在场景点的深度比较大的情况下, 全局大气光照 $A$ 对观察到的图像而言也是很重要的一个量.   


## 3. Static Image Dehazing - 单张图片去雾    

去雾算法流程图:   

```flow 
st=>start: 输入含雾图片 
e=>end: 去雾后的图片 
op1=>operation: 估计全局大气光照
op2=>operation: 估计 block 的透射率
op3=>operation: 修正透射率
op4=>operation: 去雾
st->op1->op2->op3->op4->e 
```

**具体流程**:  

(1) 根据输入图估计全局大气光照值 A;  
(2) 估计 block 的透射率. 假设: 一个 block 中像素的场景深度相同. 然后会为每个 block 找到一个最优透射率使得图像的对比度最大化;  
(3) 控制信息失真程度. 最大化对比度时产生的像素值截断会导致图像信息失真, 因此, 需要使用信息 cost 函数控制失真程度;  
(4) 精修 block 透射率为 pixel 透射率. 采用边缘保持算法和移动窗口;  
(5) 使用透射率图和全局大气光照值恢复输入图像的场景辐射度.   

### 3.1  全局大气光照估计   

因为雾会导致图像颜色变亮, 一般认为图像中最亮的颜色就是全局大气光照 $\textbf{A}$.   

但是图像中会存在这样一些目标, 它们的颜色比全局大气光照亮. 因此, 按照上述方法估计得到的全局大气光照值就会出现偏差.   

为了更好滴地估计全局大气光照值, 我们遵循以下事实: **含雾区域的像素值的方差通常都很低** 来估计全局大气光照值 $\textbf{A}$.  

另外, 我们提出了基于四叉树的层级搜索, 如下图所示:  

![](/computer_vision/image_process/doc/defrog/snapshots/video_dehazing_air_light_est.png)

分两步进行:   

1) 将输入图像分为 4 个矩形区域, 将每个区域的 "均值和标准差之差" 作为指标, 根据这个指标在 4 个区域内选择最高的区域. 继续对其 4 分切割, 直到矩形区域达到我们预先设定的区域 Size 阈值时分割结束, 得到一个最优区域;  
2) 在得到的这个区域内, 计算使这个式子 $\|(I_r(p), I_g(p), I_b(p)) - (255, 255, 255)\|$ 最小的像素点作为全局大气光照值. 之所以减去 (255, 255, 255), 是因为这样可以保证选取到很亮的全局大气光照值 A.  

****
### 3.2 估计最优透射率 - $\tilde{t}$   
****

**假设: 场景中的深度是局部相似的.** 即, 一个给定区域内的目标的场景深度值是相同的.    

那么对于一个 32x32 的 block 来说, 块内所有像素对应的透射率值相同. 如果找到一个透射率值 t, 就可以重写公式(1)为:   

$$\tag{3}
\textbf{J}(p) = \frac{1}{t}(\textbf{I}(p) - \textbf{A}) + \textbf{A}
$$

只要全局大气光照值 A 已知, 那么只需要计算出透射率值 t 就可以恢复场景的辐射度 $\textbf{J}(p)$.  

通常情况下, 带雾 block 的对比度很低, 如果估计的透射率 t 越低, 恢复后图像的对比度的增量就越大. 因此可以通过 "最大化 block 的对比度" 来得到 t 的最优估计.   

**3 种常用的对比度量化指标**  

**(1) Mean Square Error(MSE) 对比度**    

$$\tag{4}
C_\text{MSE} = \sum_{p = 1}^N{\frac{(J_c(p) - \bar{J}_c)^2}{N}}
$$

其中,   

- $c \in \{r, g, b\}$ 表示 R/G/B 索引;    
- $\bar{J}_c$ 是 $J_c(p)$ 的均值, N 是 block 中所有像素的个数;  

把 (3) 式 带入式 (4), 则 $C_\text{MSE}$ 可以被重写为:   

$$\tag{5}
C_\text{MSE} = \sum_{p = 1}^N{\frac{(I_c(p) - \bar{I}_c)^2}{t^2N}}
$$

其中,    

- $\bar{I}_c$ 是输入块中 $I_c(p)$ 的均值, 输入块中的所有像素个数为 N; 

**(2) Michelson 对比度**   

Michelson 对比度通常用于具有周期型图案和纹理的图片. 通过计算最小值和最大值之间的差异.  

$$\tag{6}
C_\text{Michelson} = \frac{J_\text{c,max}(p) - J_\text{c,min}(p)}{J_\text{c,max}(p) + J_\text{c,min}(p)}
$$

其中, 

- $J_\text{c,max}(p)$ 和 $J_\text{c,min}(p)$ 分别表示像素块内的最大像素值和最小像素值;   

把 (3) 式 带入式 (6), 则 $C_\text{Michelson}$ 可以被重写为:   

$$\tag{7}
C_\text{Michelson} = \frac{I_\text{c,max}(p) - I_\text{c,min}(p)}{I_\text{c,max}(p) + I_\text{c,min}(p) + 2A_c(t-1) }
$$

可以看到, $C_\text{Michelson}$ 和 t 互为负相关.  

**(3) Weber 对比度**   

Weber 对比度衡量的是归一化的 "背景颜色和目标颜色的差异".   

$$\tag{8}
C_\text{Weber} = \frac{J_\text{c,object}(p) - J_\text{c,background}(p)}{J_\text{c,background}(p)}
$$

在实际中, 目标颜色对应的就是每个单独的像素值, 背景颜色就是像素块内的所有像素的均值. 因此 $C_\text{Weber}$ 可以被重写为:   

$$\tag{9}
C_\text{Weber} = \sum_{p = 1}^{N}\frac{|J_\text{c}(p) - \bar{J}_\text{c}|}{N\bar{J}_\text{c}}
$$

可以看到公式 (9) 和公式 (4) 很相似.    

**说明: 本论文中采用 MSE 对比度, 但是另外两种对比度量化指标在去雾应用中同样有效.**   

由上可以得出 **结论 1**:    

- 对比度和透射率 t 成反比, 即要使最终恢复出来的图像的对比度越大, 就应该选择较小的 t;    

**Information Loss - 图像失真程度**   

根据公式 (3) 可得, 输出和输入图像的关系是一次线性关系, 函数关系如下图所示:   

![](/computer_vision/image_process/doc/defrog/snapshots/video_dehazing_information_loss.png)

输入像素值在 [$\alpha$, $\beta$] 之间的部分映射到输出像素值的 [0, 255]. 而透射率 $t$ 的值决定了输入像素值的有效区间 [$\alpha$, $\beta$]. 在此区间内的输入像素值可以获得更高的对比度, 而在此区间之外的输入像素值则无法映射到 [0, 255] 区间内(输出像素值发生上溢/下溢), 从而需要将输出像素值截断到 [0, 255] 区间内. 

截断会不可避免地导致恢复出的图像色彩信息失真, 因此, 红色区域越大, 图像色彩信息失真的程度越严重.  

根据上图中可以计算出:   

$\alpha = (t-1)A$;     

$\beta = 255t - (t-1)A$;  

$\beta-\alpha  = (255-2A)t + 2A$.   

$A$ 是第一步中估计出的全局大气光照值. 这是一个一次线性函数, $t$ 的值越大, $\beta-\alpha$ 就越大, 被截断的区间范围越小, 信息丢失也就越少.    

以下是 $t$ 取较大值和较小值对最终图像信息失真的影响效果.   

![](/computer_vision/image_process/doc/defrog/snapshots/t-vs-inforamtions_loss.png)

可以看到, $t$ 越小, 映射到输出像素值上的截断区间范围越大, 从而导致图像色彩信息失真严重.  

由上又可以得出 **结论 2**:   

- t 越小, 图像信息的丢失也就越严重;   

结合 **结论 1** 和 **结论 2**, 我们需要选择最优的 t, 以保证既有足够大的对比度, 又不至于丢失太多图像信息.   

**Cost 函数**   

根据 **结论 1** 和 **结论 2** 可知, 不仅要增强图像的对比度, 而且要减小图像色彩信息的失真程度. 因此, 引入两个 cost 函数: 对比度 cost 函数 $E_{contrast}$ 和 信息失真 cost 函数 $E_{loss}$.    

**$E_{contrast}$ 定义**, 对于每个像素块 B 的三个图像通道:  

$$\tag{10}
E_\text{contrast} = -\sum_{c \in \{r, g, b\}}\sum_{p \in B}{\frac{(J_c(p) - \bar{J}_c)^2}{N_B}} = -\sum_{c \in \{r, g, b\}}\sum_{p \in B}{\frac{(I_c(p) - \bar{I}_c)^2}{t^2N_B}}
$$

其中,   

- $N_B$ 是像素块 B 的像素数目;   

注意其中的负号 "-", 说明最小化 $E_\text{contrast}$ 可以得到最大化的 $C_\text{MSE}$.   

**$E_{loss}$定义**, 对于每个像素块 B 的三个图像通道:  

$$\tag{11}\begin{equation}\begin{aligned}
E_\text{loss} &= \sum_{c \in \{r, g, b\}}\sum_{p \in B}\left\{(min\{0, J_c(p)\})^2+(max\{0, J_c(p) - 255\})^2\right\} \\
&= \sum_{c \in \{r, g, b\}} 
\left\{
    \sum_{i = 0}^{\alpha_c}
    \left(
        \frac{i-A_c}{t}+A_c
    \right)^2h_c(i) 
    + \sum_{i = \beta_c}^{255}
    \left(
        \frac{i-A_c}{t}+A_c - 255
    \right)^2h_c(i) 
\right\} 
\end{aligned}\end{equation}$$

其中,   
- $h_c(i)$ 是输入像素值在对应颜色通道 c 上的直方图;   
- $\alpha_c$ 和 $\beta_c$ 对应上图中的截断区间;   
- min\{0, J_c(p)\} 和 max\{0, J_c(p) - 255\} 分别是由于下溢和上溢导致的像素截断;   

因此, 对于一个 block B, 我们需要找到一个 $\tilde{t}$ 使得总的 cost 函数最小:   

$$\tag{12}
E = E_\text{contrast} + \lambda_L E_\text{loss}
$$

其中,   
- $\lambda_L$ 是控制 $E_\text{contrast}$ 和 $E_\text{loss}$ 相对权重.   

直观的理解, $\lambda_L$ 越大, 说明越关心图片信息丢失的程度, 因此最终的恢复图像也会有很少的图像失真.   

### 3.3 Transmission Refinement - 修正透射率  






## 5. 实验结果   

### 5.1 static image 

使用具有代表性的五张含雾图片测试算法, 分别是 "Cones", "Forest", "House", "Town", "Plain".  

近和远的场景点分别用黄色和红色表示.  

公式(13) 中的 information loss 权重值 $\lambda_L = 5$. 

采用 information loss cost 函数, 可以保证场景点近的区域不会选择太小的透射率值, 从而不受含雾区域的影响, 产生高质量的去雾图像.  

information loss 权重值 $\lambda_L$ 大小的对比. $\lambda_L$ 过大会导致去雾不彻底, $\lambda_L$ 过小会导致对比度过分增强, 由于像素截断效果导致图像信息严重失真. 故, 本文中使用 $\lambda_L = 5$, 可以很好的权衡对比度增强和图像信息失真效果.   

和目前存在的算法进行比较.  

(1) level control 方法和直方图均衡化(histogram equalization)方法. 未考虑输入图像中雾厚度的局部变化的特性, 直接对直方图进行拉伸.  
(2) 何凯明的暗通道算法. 只考虑了最暗通道的像素值, 因此天空中白云的轮廓阴影也会被移除.  

本文提出的方法, 同时阻止了上界和下界的溢出, 因此抑制了大多数的图像处理缺陷: 比如光晕, 去雾不彻底, 过多像素值饱和.  

与何凯明的暗通道方法的详细对比(为了不引入信息失真函数, 将$\lambda_L$ 设置为 $\infty$).  

(1) 暗通道方法使用最亮的区域估计全局大气光照 A 的值, 而本文考虑了含雾区域方差小的依据, 尽量减少了含雾区域对估计 A 的影响;   
(2) 暗通道方法只考虑了暗像素(dark pixels)的截断, 而本文中的信息失真 cost 函数还考虑了亮像素(bright pixels)的截断.  

### 5.2 video  

对视频流的每一帧应用 static image 算法得到的结果中会出现闪烁. 原因是: 不同帧估计得到的全局大气光照值不同, 然后这个差异又被较小的透射率值放大, 最终严重改变原有视频帧的色调.  

这也是为什么要引入时间一致性 cost 函数的原因.  

通过观察实验结果, fast refinement 算法和未经过 fast refinement 算法得到的效果几乎是相同的.   

J. Zhang, L. Li, Y. Zhang, G. Yang, X. Cao, J. Sun, Video dehazing with spatial and
temporal coherence, Vis. Comput. 27 (6) (2011) 749–757.  

这篇文章提出的方法需要更大的内存和计算复杂度. 因为它至少使用 3 帧相邻图像来估计某一帧的透射率. 而本文提出的方法只需要前一帧的信息.  

量化指标(i5-2500k, 4G):  

- 未使用 fast refinement, 可以达到 7.5-8.1 fps;  
- 使用 fast refinement, SIMD, OpenMP 加速, 可以达到 31.6-46.1 fps.   

本文提出的视频去雾方法是如何利用时间一致性 cost 函数抑制闪烁现象的?  

评估指标:  

1) 计算相邻帧之间的 MSE 值;  
2) 使用 flicker sensitive 函数. 具体操作如下:  

- 从一个视频剪辑片段中提取每个像素点位置上的像素值, 得到一个时间序列. 
- 利用人类感知模型对这个时间序列滤波, 计算滤波后序列的时间标准差;  
- 标准差越小, 闪烁现象的抑制效果也越好.  






## 论文中依然存在的问题.   


### 0. 煤矿井下场景的特殊之处  

- 光照强度低;  
- 设备大多是金属, 反射光的特性较好;  
- 煤炭表面对于光的反射效果也较好;  
- 几乎没有颜色信息, 因此相当于单通道的灰度图像;  
- 雾是由喷雾和粉尘混合物形成;  

### 1. video 建模中的假设  

假设: 相邻两帧之间的场景的辐射率不变.  

煤矿井下场景下, 这个假设是否合适?  

### 2. 全局大气光照值 A 的估计方法  

全局大气光照值 A 的估计方法是否合适?  

较低的光照强度大大降低了大气光照值, 是否可以在一定程度上对大气光照值进行补偿?   

### 3. 由于雾的存在而导致图像完全没有场景信息   

去雾恢复的作用是, 即使雾气很浓, 但是只要有场景信息就可以得到很好的恢复效果.  

但是, 如果图像中完全是雾, 没有任何场景信息, 这是完全没有办法恢复的.   

